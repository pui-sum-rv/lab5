{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferit-osirv/lab5/blob/main/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "ipXpivMK_PT8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vtuqXEBP1j"
      },
      "source": [
        "# Lab 5 - Image Segmentation using Watershed\n",
        "\n",
        "Ove laboratorijske vježbe se rješavaju u Google Colabu i spremaju na GitHub repozitorij koji je povezan na GitHub Classroom.\n",
        "\n",
        "## Kako riješiti zadatke?\n",
        "\n",
        "1. Prihvatite zadatak putem Google Classroom linka koji ćete dobiti. Google Classroom će kreirati repozitorij na vašem računu.\n",
        "2. Uđite u novokreiran repozitorij na vašem računu i kliknite na **.ipynb** datoteku, zatim kliknite **Open in Colab**.\n",
        "3. Zadatke rješavate u Google Colabu.\n",
        "\n",
        "## Kako spremiti (predati) zadatke?\n",
        "\n",
        "1. Unutar **Google Colaba** kliknite na **Open settings** kotačić u gornjem desnom kutu.\n",
        "2. Kliknite na **GitHub** tab i odaberite kvačicu za **Access private repositories and organizations**.\n",
        "3. Otvorit će se novi prozor da dodate pristup GitHubu. Kod **ferit-osirv** kliknite **Grant**.  \n",
        "4. Spremite i izađite iz postavki.\n",
        "\n",
        "\n",
        "5. Kliknite na **File > Save a copy in GitHub**.\n",
        "6. Odaberite kreiran repozitorij labosa **koji uključuje vaše ime**.\n",
        "\n",
        "> *Napomena:* Korake 1-4 morate napraviti samo prvi put."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feUPz7IDCbDx"
      },
      "source": [
        "## Kopiranje datoteka iz GitHub repozitorija\n",
        "\n",
        "Za izradu vježbi bit će vam potrebne slike i druge datoteke koje će se nalaziti u GitHub repozitoriju vježbe. Ovakva komanda će biti dostupna u notebooku svake vježbe. Ona će kopirati datoteke s GitHuba u Google Colab okruženje.\n",
        "\n",
        "**Ovu komandu je potrebno pokrenuti prije nego što krenete raditi svaku vježbu.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpP_i0KgCefb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2dde0b2-140a-4d35-d874-ac0ab8161269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'clone'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 11 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (11/11), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf clone && git clone https://github.com/runsandshite/lab5 clone && cp -a clone/. .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIPg8Vf9Cr8D"
      },
      "source": [
        "**Google Colab će povremeno obrisati sve datoteke.** Tako da će možda biti potrebno ponovno pokrenuti ovu komandu između dvije sesije. Ako dobivate greške da datoteke ne postoje, probajte ponovno pokrenuti gornju komandu."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Very simple segmentation methods like thresholding sometimes give good results, but as soon as we have more complex images, we need more complex algorithms. One problem that thresholding can't solve is to segment overlapping objects. In the cell image below, you'll notice a lot of the cells overlap and look like they are joined. To correctly segment them, we need an algorithm that is capable of separating overlapping objects. The watershed is a classical algorithm used for segmentation, that is, for separating different objects in an image. \n",
        "\n",
        "In this lab, you'll implement a full watershed segmentation pipeline for segmenting blood cells from a microscope blood smear image (left).\n",
        "Once you're done, you'll obtain an image similar to the one in the right.\n",
        "\n",
        "[![image](https://www.linkpicture.com/q/watershed.png)](https://www.linkpicture.com/view.php?img=LPic61b78a27ee5251872959539)\n"
      ],
      "metadata": {
        "id": "P3Vbg2zGLwyD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYo2aUFyf0kX"
      },
      "source": [
        "### Watershed segmentation\n",
        "\n",
        "The term watershed refers to a ridge that divides areas drained by different river systems. A catchment basin is the geographical area draining into a river or reservoir.\n",
        "\n",
        "Any grayscale image can be viewed as a topographic surface where high intensity denotes peaks and hills while low intensity denotes valleys. You start filling every isolated valleys (local minima) with different colored water (labels). As the water rises, depending on the peaks (gradients) nearby, water from different valleys, obviously with different colors will start to merge. To avoid that, you build barriers in the locations where water merges. You continue the work of filling water and building barriers until all the peaks are under water. Then the barriers you created gives you the segmentation result. This is the \"philosophy\" behind the watershed. \n",
        "\n",
        "Lets observe this in the following example. Any greytone image can be considered as a topographic surface:\n",
        "\n",
        "\n",
        "![watershed1](https://people.cmm.minesparis.psl.eu/users/beucher/ima1.gif)\n",
        "![watershed2](https://people.cmm.minesparis.psl.eu/users/beucher/ima2.gif)\n",
        "\n",
        "If we flood this surface from its minima and, if we prevent the merging of the waters coming from different sources, we partition the image into two different sets: the catchment basins and the watershed lines.\n",
        "\n",
        "![watershed3](https://people.cmm.minesparis.psl.eu/users/beucher/lpe1.gif)\n",
        "![watershed4](https://people.cmm.minesparis.psl.eu/users/beucher/ima3.gif)\n",
        "\n",
        "If we apply this transformation to the image gradient, the catchment basins should theoretically correspond to the homogeneous grey level regions of this image. However, in practice, this transform produces an important over-segmentation due to noise or local irregularities in the gradient image.\n",
        "\n",
        "![watershed5](https://people.cmm.minesparis.psl.eu/users/beucher/ima6.gif)\n",
        "![watershed6](https://people.cmm.minesparis.psl.eu/users/beucher/ima7.gif)\n",
        "![watershed7](https://people.cmm.minesparis.psl.eu/users/beucher/ima7b.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image preprocessing for watershed"
      ],
      "metadata": {
        "id": "FLuYQAOUupfq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Distance transform as preprocessing for watershed\n",
        "\n",
        "To use watershed, you first need an image that you can treat as a smooth 3D topology map to pour water in. You can't use the original microscope image, instead, you need to convert it into a grayscale image where cells have light values and the background is black. To do this you'll use **distance transform**. Distance transform of a binary image (with pixel values 1 or 0) will give you an image where each pixel's value is the distance to its closest edge.\n",
        "\n",
        "\n",
        "![distance_transform](https://gitlab.com/habijaaan/osirv_20_21/-/raw/master/lab6/distance_transform.jpg)\n",
        "\n",
        "\n",
        "This way you transform a binary image into a smooth image where the distance to the edge is the \"height\" of the mountain."
      ],
      "metadata": {
        "id": "vSMORi0uMzKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
        "\n",
        "Contrast Limited Adaptive Histogram Equalization or CLAHE is a technique for histogram equalization, improving the contrast of the image. Bright images have only light pixel values, while dark images have only dark pixel values. Histogram equalization stretches the histogram of an image so that its values span a broader range, making both dark and bright images have the same mean pixel value.\n",
        "\n",
        "You'll use CLAHE as a preprocessing step for your algorithm. More info: https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html\n",
        "\n"
      ],
      "metadata": {
        "id": "ccfajpSGM8Pk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Morphological operators for removing noise in images\n",
        "\n",
        "Morphological operators take a binary image and a structuring element as input and combine them using a set operator (intersection, union, inclusion, complement). They process objects in the input image based on characteristics of its shape, which are encoded in the structuring element. \n",
        "\n",
        "Usually, the structuring element is sized 3×3 and has its origin at the center pixel. It is shifted over the image and at each pixel of the image its elements are compared with the set of the underlying pixels. For the basic morphological operators the structuring element contains only foreground pixels (i.e. ones) and 'don't care's'. These operators, which are all a combination of erosion and dilation, are often used to select or suppress features of a certain shape, e.g. removing noise from images or selecting objects with a particular direction.\n",
        "The more sophisticated operators take zeros as well as ones and 'don't care's' in the structuring element. The most general operator is the hit and miss, in fact, all the other morphological operators can be deduced from it. Its variations are often used to simplify the representation of objects in a binary image while preserving their structure, e.g. producing a skeleton of an object using skeletonization and tidying up the result using thinning.\n",
        "\n",
        "The common morphological operations are:\n",
        "\n",
        "*  Dilation - grow image regions\n",
        "*  Erosion - shrinks image regions\n",
        "*  Opening - structured removal of image region boundary pixels\n",
        "*  Hit and miss transform - image pattern matching and marking\n",
        "*  Thining - structured erosion using image pattern matching\n",
        "*  Thickening - structured dilation using image pattern mathcinh\n",
        "*  Skeletonization - finding skeletons of binary regions \n",
        "\n",
        "You'll use morphological opening and dilation as a preprocessing step for your algorithm. \n",
        "More info: https://docs.opencv.org/3.4/d9/d61/tutorial_py_morphological_ops.html\n"
      ],
      "metadata": {
        "id": "tj6qZ_PkwdJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Watershed Segmentation steps \n",
        "\n",
        "So, to segment your image, here's what you'll do:\n",
        "\n",
        "1. Convert the microscope image into grayscale.\n",
        "2. Perform CLAHE on the grayscale image to accentuate cell edges.\n",
        "3. Threshold the image so you get a binary image where cells are white and the background is black.\n",
        "4. Use morphological operators to remove noise from that binary image.\n",
        "5. Use distance transform on the binary image.\n",
        "6. Threshold the distance transform to obtain markers.\n",
        "7. Apply watershed with the obtained markers to get the final segmentation.\n",
        "\n"
      ],
      "metadata": {
        "id": "wp-kRwOrNTJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assignments \n",
        "\n",
        "Your assignment is to fill in code in the # TODO comments in the code. \n",
        "\n",
        "1. Compare your saved images with the ones named <image>_example.png to make sure your code works.\n",
        "2. Rename your result.png image into result_original.png. Then, comment out gray = clahe(gray). \n",
        "3. Run the code again and compare the new result.png to your original one. \n",
        "4. Add a comment at the bottom explaining what differences you see and why those differences are there.\n",
        "5. Annotate your result image however you like (using any image editing tool) to show (a) one example of oversegmentation on the image and (b) one example of undersegmentation on the image."
      ],
      "metadata": {
        "id": "LQqIlLSlNxaq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXS_YJC2WsWD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from google.colab.patches import cv2_imshow  \n",
        "import random as rng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmcUh7OoKoRp"
      },
      "outputs": [],
      "source": [
        "# Load the source image\n",
        "img = cv.imread('images/cells.jpg')\n",
        "cv2_imshow(img)\n",
        "# Convert image to grayscale\n",
        "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)\n",
        "# Apply CLAHE\n",
        "#gray = clahe(gray)\n",
        "# OTSU threshold the image \n",
        "#TODO:\n",
        "thresh =\n",
        "cv.imwrite(\"images/thresholded.png\", thresh[1])\n",
        "cv2_imshow(thresh[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYnOuEBkKt3L"
      },
      "outputs": [],
      "source": [
        "# Use morphological processing to remove noise from the image\n",
        "# use 3x3 structuring element and opening operations\n",
        "#TODO:\n",
        "kernel = \n",
        "#TODO:\n",
        "opening = \n",
        "cv2_imshow(opening)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8eBR95aKwXc"
      },
      "outputs": [],
      "source": [
        "# Finding sure background area\n",
        "#TODO:\n",
        "sure_bg = \n",
        "cv2_imshow(sure_bg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDWWq2BvKy4L"
      },
      "outputs": [],
      "source": [
        "# Apply distance transform the image\n",
        "dist_transform =  cv.distanceTransform(thresh[1], cv.DIST_L2, 3)\n",
        "# Normalize so that the distance transform image has minimum and maximum values from 0 to 1\n",
        "cv.normalize(dist_transform, dist_transform, 0, 1.0, cv.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cv.imwrite(\"images/distance_transform.png\", dist_transform * 255)\n",
        "cv2_imshow(dist_transform*255)"
      ],
      "metadata": {
        "id": "8yGCG9c7K3lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sure foreground area is where the distance transform has the highest values,\n",
        "# so threshold the image so that every pixel below 0.2 is set to 0\n",
        "ret, sure_fg = cv.threshold(dist_transform, 0.2*dist_transform.max(), 255, 0)"
      ],
      "metadata": {
        "id": "SVYu6QalK4Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding unknown region, i.e. the difference between sure foreground and sure background (the edges of the cells)\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "unknown = cv.subtract(sure_bg,sure_fg)"
      ],
      "metadata": {
        "id": "XbM3SNucK5Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find areas of connected pixels - we call these markers\n",
        "ret, markers = cv.connectedComponents(sure_fg)\n",
        "# Add one to all markers so that sure background is not 0, but 1\n",
        "markers = markers+1\n",
        "# Now, mark the region of unknown with zero\n",
        "markers[unknown==255] = 0"
      ],
      "metadata": {
        "id": "7cHbwMtIK9-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, apply watershed to the image using the markers as guides\n",
        "markers = cv.watershed(img, markers)"
      ],
      "metadata": {
        "id": "0RW4j_OUK9wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random colors\n",
        "colors = []\n",
        "for i in range(markers.shape[0] * markers.shape[1]):\n",
        "  colors.append((rng.randint(0,256), rng.randint(0,256), rng.randint(0,256)))"
      ],
      "metadata": {
        "id": "C5014OkDLCOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the result image\n",
        "dst = np.zeros((markers.shape[0], markers.shape[1], 3), dtype=np.uint8)\n",
        "# Fill labeled objects with random colors\n",
        "for i in range(markers.shape[0]):\n",
        "    for j in range(markers.shape[1]):\n",
        "        index = markers[i,j]\n",
        "        dst[i,j,:] = colors[index-1]\n",
        "\n",
        "cv2_imshow(dst)\n",
        "cv.imwrite(\"images/result.png\", dst)"
      ],
      "metadata": {
        "id": "iT29BJ_5LFbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8d2bk0_f0kw"
      },
      "source": [
        "Ne zaboravite spremiti zadatke na GitHub!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy_of_lab1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
